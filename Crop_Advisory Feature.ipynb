{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OScjY4DbJ6Jy",
        "outputId": "928c994e-a915-411f-a086-b8218db365b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr-urd is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# üß∞ System Dependencies (Poppler + Urdu OCR)\n",
        "!apt-get -y install poppler-utils tesseract-ocr tesseract-ocr-urd\n",
        "\n",
        "# üß™ Python Libraries\n",
        "!pip install -q \\\n",
        "    gradio \\\n",
        "    groq \\\n",
        "    langchain \\\n",
        "    langchain-community \\\n",
        "    langchain-huggingface \\\n",
        "    pytesseract \\\n",
        "    pdf2image \\\n",
        "    requests \\\n",
        "    Pillow \\\n",
        "    torch \\\n",
        "    sentence-transformers \\\n",
        "    faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =======================\n",
        "# üåæ Crop Advisory ‚Äî build once, reuse FAISS\n",
        "# =======================\n",
        "import os, re, json, shutil\n",
        "from io import BytesIO\n",
        "import requests\n",
        "from pdf2image import convert_from_bytes\n",
        "import pytesseract\n",
        "import gradio as gr\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from groq import Groq\n",
        "\n",
        "# ---------- Config ----------\n",
        "INDEX_DIR   = \"/content/faiss_urdu_index\"\n",
        "EMBED_MODEL = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "GROQ_MODEL  = \"llama3-70b-8192\"\n",
        "\n",
        "# üîê Read key from environment (recommended: set with os.environ[\"GROQ_API_KEY\"]=\"...\")\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\", \"\")\n",
        "\n",
        "# Replace with your own Drive links\n",
        "DRIVE_LINKS = {\n",
        "    \"PDF 1\": \"https://drive.google.com/file/d/16VRkuegHXbhQPPH6kB3jTcdlg1eh95Og/view?usp=sharing\",\n",
        "    \"PDF 2\": \"https://drive.google.com/file/d/1e4Zi9vYXHEtuU_mkpBKDjZ-s0fIFqdzO/view?usp=sharing\",\n",
        "    \"PDF 3\": \"https://drive.google.com/file/d/149Js-w01KO085cRibqXyra9_oPNRAYqZ/view?usp=sharing\"\n",
        "}\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "def _download_pdf_from_drive(drive_link: str):\n",
        "    try:\n",
        "        file_id = drive_link.split(\"/d/\")[1].split(\"/\")[0]\n",
        "        url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "        r = requests.get(url, timeout=60)\n",
        "        r.raise_for_status()\n",
        "        if r.content[:4] != b\"%PDF\":\n",
        "            raise ValueError(\"Not a PDF (Drive interstitial?)\")\n",
        "        return BytesIO(r.content)\n",
        "    except Exception as e:\n",
        "        print(\"Download error:\", e); return None\n",
        "\n",
        "def _clean(t: str) -> str:\n",
        "    t = re.sub(r\"\\.{2,}\", \".\", t)\n",
        "    t = re.sub(r\"\\n+\", \"\\n\", t)\n",
        "    t = re.sub(r\" +\", \" \", t)\n",
        "    return t.strip()\n",
        "\n",
        "def extract_text_urdu(links: dict, max_pages=2) -> str:\n",
        "    \"\"\"OCR first `max_pages` of each PDF in Urdu.\"\"\"\n",
        "    all_text = \"\"\n",
        "    for title, url in links.items():\n",
        "        f = _download_pdf_from_drive(url)\n",
        "        if not f:\n",
        "            continue\n",
        "        try:\n",
        "            for img in convert_from_bytes(f.read())[:max_pages]:\n",
        "                all_text += pytesseract.image_to_string(img, lang=\"urd\") + \"\\n\"\n",
        "        except Exception as e:\n",
        "            print(f\"OCR failed for {title}:\", e)\n",
        "    return _clean(all_text)\n",
        "\n",
        "def chunk_text(text: str):\n",
        "    return RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50).create_documents([text])\n",
        "\n",
        "def index_exists() -> bool:\n",
        "    return os.path.isdir(INDEX_DIR) and os.path.exists(os.path.join(INDEX_DIR, \"index.faiss\"))\n",
        "\n",
        "def build_index(links: dict) -> str:\n",
        "    try:\n",
        "        if index_exists():\n",
        "            shutil.rmtree(INDEX_DIR)\n",
        "        text = extract_text_urdu(links)\n",
        "        if not text.strip():\n",
        "            return \"‚ùå No text extracted. Check OCR/links.\"\n",
        "        docs = chunk_text(text)\n",
        "        embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
        "        db = FAISS.from_documents(docs, embedding=embeddings)\n",
        "        db.save_local(INDEX_DIR)\n",
        "        with open(os.path.join(INDEX_DIR, \"manifest.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump({\"docs\": len(docs), \"model\": EMBED_MODEL}, f, ensure_ascii=False, indent=2)\n",
        "        return f\"‚úÖ Built index: {len(docs)} chunks\"\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Build error: {e}\"\n",
        "\n",
        "def load_index():\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
        "    return FAISS.load_local(INDEX_DIR, embeddings, allow_dangerous_deserialization=True)\n",
        "\n",
        "# Lazy global cache\n",
        "_db = None\n",
        "def get_db():\n",
        "    global _db\n",
        "    if _db is None and index_exists():\n",
        "        _db = load_index()\n",
        "    return _db\n",
        "\n",
        "# ---------- QA ----------\n",
        "def answer_query(q: str) -> str:\n",
        "    if not GROQ_API_KEY:\n",
        "        return \"‚ùå GROQ_API_KEY not set. Please set it in the environment.\"\n",
        "    db = get_db()\n",
        "    if db is None:\n",
        "        return \"‚ùå No index found. Go to Admin tab and Build.\"\n",
        "    hits = db.similarity_search(q, k=3)\n",
        "    if not hits:\n",
        "        return \"‚ùå No relevant information found.\"\n",
        "\n",
        "    context = \"\\n\\n\".join([h.page_content for h in hits])\n",
        "\n",
        "    # ‚ñ∂Ô∏è Pointer-style bilingual prompt (English + Urdu)\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful agricultural advisor. Use ONLY the following Urdu context to answer the user's question.\n",
        "Respond in BOTH English and Urdu. Format your answer as clear bullet points (‚Ä¢) with short, actionable guidance.\n",
        "Avoid long paragraphs. Where appropriate, add quantities/doses.\n",
        "\n",
        "---\n",
        "{context}\n",
        "---\n",
        "\n",
        "Question: {q}\n",
        "\n",
        "Answer in bullet points, first English then Urdu:\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        client = Groq(api_key=GROQ_API_KEY)\n",
        "        resp = client.chat.completions.create(\n",
        "            model=GROQ_MODEL,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "        return resp.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Groq error: {e}\"\n",
        "\n",
        "# ---------- Gradio ----------\n",
        "with gr.Blocks(title=\"Crop Advisory\") as demo:\n",
        "    gr.Markdown(\"## üåæ Crop Advisory\\nAsk crop care, pest control, irrigation, and fertilizer questions (English or Roman Urdu).\")\n",
        "\n",
        "    with gr.Tab(\"üß† Ask\"):\n",
        "        q = gr.Textbox(label=\"üí¨ Your question\", lines=2, placeholder=\"e.g., Best time to irrigate wheat in winter?\")\n",
        "        a = gr.Textbox(label=\"üìò Advisory (Bulleted ‚Ä¢ English ‚Üí Urdu)\", lines=12, show_copy_button=True)\n",
        "        gr.Button(\"üîé Get Advisory\").click(answer_query, q, a)\n",
        "\n",
        "    with gr.Tab(\"üõ† Admin\"):\n",
        "        gr.Markdown(\"Build / Rebuild the FAISS index from Google Drive PDFs (Urdu OCR).\")\n",
        "        links_in = gr.Textbox(label=\"Google Drive links (JSON dict)\", value=json.dumps(DRIVE_LINKS, indent=2), lines=8)\n",
        "        status = gr.Textbox(label=\"Status\")\n",
        "\n",
        "        def build_action(json_links):\n",
        "            try:\n",
        "                links = json.loads(json_links)\n",
        "            except Exception as e:\n",
        "                return f\"‚ùå Invalid JSON: {e}\"\n",
        "            global _db; _db = None  # reset cache\n",
        "            return build_index(links)\n",
        "\n",
        "        gr.Button(\"‚öôÔ∏è Build / Rebuild Index\").click(build_action, links_in, status)\n",
        "\n",
        "        def check():\n",
        "            if not index_exists():\n",
        "                return \"‚ùå No index on disk.\"\n",
        "            man_path = os.path.join(INDEX_DIR, \"manifest.json\")\n",
        "            man = json.load(open(man_path)) if os.path.exists(man_path) else {}\n",
        "            return f\"‚úÖ Index present\\nChunks: {man.get('docs','?')}\\nModel: {man.get('model','?')}\\nPath: {INDEX_DIR}\"\n",
        "        gr.Button(\"üîé Check Index\").click(lambda: check(), outputs=status)\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "U8Of9VJYJ_2O",
        "outputId": "41d9a1c2-04e5-40f7-8dda-67242f21ffe0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0ea4393ac1990202dd.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0ea4393ac1990202dd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UIGe5i3eMjWK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}